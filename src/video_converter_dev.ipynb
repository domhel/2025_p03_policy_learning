{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96316ca2",
   "metadata": {},
   "source": [
    "# Notes from example\n",
    "- telling names for functions\n",
    "- use type hinting for arguments and function returns\n",
    "- 1 feature per function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc058cd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Produktiv-Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7f217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from accelerate.test_utils.testing import get_backend\n",
    "from transformers import pipeline, Pipeline\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead18015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Handling\n",
    "#TODO: Prüfe Nachbearbeitung Bild erforderlich\n",
    "#TODO: Data-Import like in Example\n",
    "\n",
    "def open_video(path: str) -> cv2.VideoCapture:\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        exit()\n",
    "    return cap\n",
    "\n",
    "def next_image_from_video(cap: cv2.VideoCapture) -> Optional[Image.Image]:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return None\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(frame_rgb)\n",
    "    return image\n",
    "\n",
    "def image_to_video(image: str, video_writer: cv2.VideoWriter):\n",
    "    #GGF noch postprocessing des videos, z.B. Normalisieren\n",
    "    #TODO Übergabe Bildtyp anpassen und cv2 Umwandlung korrekt auswählen\n",
    "    # Achtung: VideoWriter erwartet 3 Kanäle, wenn isColor=True – also ggf. Graustufenbild nach BGR konvertieren\n",
    "    depth_bgr = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Frame ins Video schreiben\n",
    "    video_writer.write(depth_bgr)\n",
    "\n",
    "def apply_model(frame: Image.Image ,model_selection: str) -> Image.Image:\n",
    "    device, _, _ = get_backend()\n",
    "    if model_selection == \"Depth-Anything-V2-base-hf\":\n",
    "        checkpoint = \"depth-anything/Depth-Anything-V2-base-hf\"\n",
    "        pipe = pipeline(\"depth-estimation\", model=checkpoint, device=device)\n",
    "        predictions = pipe(frame)\n",
    "        image_w_pred = predictions['depth']\n",
    "\n",
    "    # If all models are called in the same way via the transformers library/pipeline, we can remove the general part and only put the parameterization in the if clause\n",
    "\n",
    "    return image_w_pred\n",
    "\n",
    "def get_videowriter(cap: cv2.VideoCapture, target_path: str) -> cv2.VideoWriter:\n",
    "    # Video Schreiber erstellen\n",
    "    # Videoeigenschaften holen\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # VideoWriter vorbereiten (MP4 mit H.264)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Alternativ: 'avc1', 'XVID', 'H264'\n",
    "    video_writer = cv2.VideoWriter(target_path, fourcc, fps, (width, height), isColor=False)\n",
    "\n",
    "def convert_video(path: str):\n",
    "    # Video durchlaufen, Fehlermeldungen berücksichtigen\n",
    "    cap = open_video(path)\n",
    "\n",
    "    target_path = \"\" #TODO Funktion zur Definition des Targetpath \n",
    "    #Video Ausgabe initialisieren\n",
    "    video_writer = get_videowriter(cap,target_path)\n",
    "\n",
    "    #TODO Schleife zum Video-Durchlauf\n",
    "    #TODO sicheres Abfangen von Fehlern beim Video öffnen\n",
    "    next_image_from_video(cap)\n",
    "    new_image = apply_model()\n",
    "    image_to_video(new_image)\n",
    "    \n",
    "    cap.release()\n",
    "    video_writer.release() #Nach schließen wird das Video abgespeichert\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa661af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Test Snippets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
